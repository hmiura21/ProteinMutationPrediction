{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpYk4dHcJyxN"
   },
   "source": [
    "# Example script for Hackathon\n",
    "\n",
    "Within each cycle of active learning, you can:\n",
    "\n",
    "1. Collect training data (original training data + your query data).\n",
    "\n",
    "2. Train a prediction model to predict the DMS_score for each mutant (e.g., M0A).\n",
    "\n",
    "3. Use the trained model to predict the score for all mutant in the test set.\n",
    "\n",
    "4. Select query mutants for next round based on certain criteria. You may want to make sure you don't query the same mutant twice as you only have a limited chances of making queries in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PDuz5mihLReY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure parameters \n",
    "config = {\n",
    "    \"learning_rate\": 9e-5,\n",
    "    \"batch_size\": 8,\n",
    "    \"num_epochs\": 5,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"esm_model_name\": \"esm2_t33_650M_UR50D\", \n",
    "    \"embedding_layer\": 33, #Final layer for the esm model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9WI5oTTKdIY"
   },
   "source": [
    "## 1. collect training data\n",
    "\n",
    "Upload `sequence.fasta`, `train.csv`, and `test.csv` to the current runtime:\n",
    "\n",
    "1. click the folder icon on the left\n",
    "\n",
    "2. click the upload icon and upload the files to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "Tj-TUAeZLEUz",
    "outputId": "88a181fb-fa9f-4954-caab-f7342a9d0b97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNARETEAP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_fasta(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Skip header lines (starting with \">\")\n",
    "    seq = \"\".join([line.strip() for line in lines if not line.startswith(\">\")])\n",
    "    return seq\n",
    "\n",
    "sequence_wt = read_fasta('sequence.fasta')\n",
    "sequence_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dewLzhLYMUSJ",
    "outputId": "f2c11453-a976-4778-f30d-57321d41e5d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N-tkTaqtK9AD"
   },
   "outputs": [],
   "source": [
    "def get_mutated_sequence(mut, sequence_wt):\n",
    "  wt, pos, mt = mut[0], int(mut[1:-1]), mut[-1]\n",
    "\n",
    "  sequence = deepcopy(sequence_wt)\n",
    "\n",
    "  return sequence[:pos]+mt+sequence[pos+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mutant_sequence(sequence_wt, mut):\n",
    "    return get_mutated_sequence(mut, sequence_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bZH3YKNVyR-m",
    "outputId": "efff26ca-ec20-4bdc-9473-c3ebe01e996d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>DMS_score</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0Y</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0W</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0V</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0T</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0S</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>P347D</td>\n",
       "      <td>0.3876</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>P347C</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>P347A</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>P347M</td>\n",
       "      <td>0.2412</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>P347H</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mutant  DMS_score                                           sequence\n",
       "0       M0Y     0.2730  YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1       M0W     0.2857  WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2       M0V     0.2153  VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3       M0T     0.3122  TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4       M0S     0.2180  SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...     ...        ...                                                ...\n",
       "1135  P347D     0.3876  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1136  P347C     0.1837  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1137  P347A     0.4611  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1138  P347M     0.2412  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1139  P347H     0.1512  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[1140 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train['sequence'] = df_train.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tqfIASlMLQe4",
    "outputId": "8a13634d-f9cd-4e3d-e7fb-efa11438e6a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1E</td>\n",
       "      <td>MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>P655S</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>P655T</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>P655V</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>P655A</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11324 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mutant                                           sequence\n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4        V1E  MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...      ...                                                ...\n",
       "11319  P655S  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11320  P655T  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11321  P655V  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11322  P655A  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[11324 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['sequence'] = df_test.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating first set of query data:\n",
    "df_query_new = pd.read_csv('queried_data.csv')\n",
    "df_query_new['sequence'] = df_query_new['mutant'].apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train = pd.concat([df_train, df_query_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating second set of query data:\n",
    "df_query_new2 = pd.read_csv('queried_data2.csv')\n",
    "df_query_new2['sequence'] = df_query_new2['mutant'].apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train = pd.concat([df_train, df_query_new2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating third set of query data:\n",
    "df_query_new3 = pd.read_csv('queried_data3.csv')\n",
    "df_query_new3['sequence'] = df_query_new3['mutant'].apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train = pd.concat([df_train, df_query_new3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mutant  DMS_score                                           sequence\n",
      "0       M0Y   0.273000  YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "1       M0W   0.285700  WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "2       M0V   0.215300  VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "3       M0T   0.312200  TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "4       M0S   0.218000  SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "...     ...        ...                                                ...\n",
      "1435  L639H   0.476989  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "1436  L639D   0.704033  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "1437  P655Y   0.645727  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "1438  P655F   0.727330  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "1439  P655W   0.596169  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
      "\n",
      "[1440 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B8hiStmfLXz6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1296, 3)\n",
      "Validation set shape: (144, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split train into training and validation sets\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.1, random_state=42)\n",
    "print(\"Training set shape:\", df_train.shape)\n",
    "print(\"Validation set shape:\", df_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cty7BGBLdgp"
   },
   "source": [
    "## 2. Train a prediction model\n",
    "\n",
    "Here, we provided a linear regression model and used one-hot encoding to encode each variant. You would need to build your own model to achieve better performances.\n",
    "\n",
    "Hint: you can perform cross-validation on the training set to evaluate your predictor before making predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fair-esm in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (2.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: biopython in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (1.85)\n",
      "Requirement already satisfied: numpy in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from biopython) (1.24.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from peft) (0.29.3)\n",
      "Requirement already satisfied: tqdm in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: psutil in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from peft) (4.50.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from peft) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from peft) (23.0)\n",
      "Requirement already satisfied: pyyaml in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2025.2.0)\n",
      "Requirement already satisfied: requests in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: networkx in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hice1/hmiura3/.local/lib/python3.10/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm\n",
    "!pip install biopython\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESM2',\n",
       " 'Namespace',\n",
       " 'Path',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_download_model_and_regression_data',\n",
       " '_has_regression_weights',\n",
       " '_load_model_and_alphabet_core_v1',\n",
       " '_load_model_and_alphabet_core_v2',\n",
       " 'esm',\n",
       " 'esm1_t12_85M_UR50S',\n",
       " 'esm1_t34_670M_UR100',\n",
       " 'esm1_t34_670M_UR50D',\n",
       " 'esm1_t34_670M_UR50S',\n",
       " 'esm1_t6_43M_UR50S',\n",
       " 'esm1b_t33_650M_UR50S',\n",
       " 'esm1v_t33_650M_UR90S',\n",
       " 'esm1v_t33_650M_UR90S_1',\n",
       " 'esm1v_t33_650M_UR90S_2',\n",
       " 'esm1v_t33_650M_UR90S_3',\n",
       " 'esm1v_t33_650M_UR90S_4',\n",
       " 'esm1v_t33_650M_UR90S_5',\n",
       " 'esm2_t12_35M_UR50D',\n",
       " 'esm2_t30_150M_UR50D',\n",
       " 'esm2_t33_650M_UR50D',\n",
       " 'esm2_t36_3B_UR50D',\n",
       " 'esm2_t48_15B_UR50D',\n",
       " 'esm2_t6_8M_UR50D',\n",
       " 'esm_if1_gvp4_t16_142M_UR50',\n",
       " 'esm_msa1_t12_100M_UR50S',\n",
       " 'esm_msa1b_t12_100M_UR50S',\n",
       " 'esmfold_v0',\n",
       " 'esmfold_v1',\n",
       " 'has_emb_layer_norm_before',\n",
       " 'load_hub_workaround',\n",
       " 'load_model_and_alphabet',\n",
       " 'load_model_and_alphabet_core',\n",
       " 'load_model_and_alphabet_hub',\n",
       " 'load_model_and_alphabet_local',\n",
       " 'load_regression_hub',\n",
       " 're',\n",
       " 'torch',\n",
       " 'urllib',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import esm\n",
    "dir(esm.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ESM model as specified in our config\n",
    "model, alphabet = esm.pretrained.__dict__[config[\"esm_model_name\"]]()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.modules import RobertaLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ESM2(\n",
       "      (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0-32): 33 x TransformerLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (rot_emb): RotaryEmbedding()\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (contact_head): ContactPredictionHead(\n",
       "        (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure LoRA\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,                # Low-rank dimension\n",
    "    lora_alpha=16,      # Scaling factor \n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention projection layers \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Wrap the ESM model with LoRA adapters\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.train()  # Set to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 651719094\n",
      "Trainable parameters (LoRA adapters + unfrozen layers): 675840\n"
     ]
    }
   ],
   "source": [
    "# Verify parameter counts\n",
    "num_total = sum(p.numel() for p in model.parameters())\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {num_total}\")\n",
    "print(f\"Trainable parameters (LoRA adapters + unfrozen layers): {num_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a new dataset that returns raw sequences.\n",
    "class ProteinDatasetRaw(Dataset):\n",
    "    def __init__(self, df, wt_seq):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.wt_seq = wt_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        mutation = row['mutant']\n",
    "        label = row['DMS_score'] if 'DMS_score' in self.df.columns else None\n",
    "        mutated_seq = generate_mutant_sequence(self.wt_seq, mutation)\n",
    "        return {\"sequence\": mutated_seq, \"label\": label, \"mutation\": mutation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert raw to token\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "def collate_fn(batch):\n",
    "    sequences = [item[\"sequence\"] for item in batch]\n",
    "    # creat tokens\n",
    "    batch_data = [(\"protein{}\".format(i), seq) for i, seq in enumerate(sequences)]\n",
    "    _, _, tokens = batch_converter(batch_data)\n",
    "    tokens = tokens.to(device)\n",
    "    # For training/validation batches, also gather labels\n",
    "    if \"label\" in batch[0] and batch[0][\"label\"] is not None:\n",
    "        labels = [item[\"label\"] for item in batch]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        labels = None\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets and loaders\n",
    "train_dataset_raw = ProteinDatasetRaw(df_train, sequence_wt)\n",
    "valid_dataset_raw = ProteinDatasetRaw(df_valid, sequence_wt)\n",
    "train_loader = DataLoader(train_dataset_raw, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset_raw, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMWithLMHead(nn.Module):\n",
    "    def __init__(self, esm_model, embedding_layer):\n",
    "        super(ESMWithLMHead, self).__init__()\n",
    "        self.esm_model = esm_model  \n",
    "        self.embedding_layer = embedding_layer\n",
    "        # initialize  LM head with 33 layers to extract embedings\n",
    "        self.lm_head = RobertaLMHead(\n",
    "            embed_dim=self.esm_model.embed_dim,         # 1280\n",
    "            output_dim=self.esm_model.alphabet_size,      # 33\n",
    "            weight=self.esm_model.embed_tokens.weight,    \n",
    "        )\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        results = self.esm_model(tokens, repr_layers=[self.embedding_layer], return_contacts=False)\n",
    "        token_representations = results[\"representations\"][self.embedding_layer]  \n",
    "        # Average pooling over tokens \n",
    "        pooled = token_representations[:, 1:-1].mean(dim=1) \n",
    "        lm_out = self.lm_head(pooled)  \n",
    "        # Aggregate the output into a scalar fitness prediction by taking the mean\n",
    "        fitness_pred = lm_out.mean(dim=1) \n",
    "        return fitness_pred\n",
    "\n",
    "# combine model with ESM and embedding layer\n",
    "combined_model = ESMWithLMHead(model, config[\"embedding_layer\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=config[\"learning_rate\"])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    for tokens, labels in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tokens)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * tokens.size(0)\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    return running_loss / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.1799, Train Spearman: 0.3180, Val Loss: 0.0955, Val Spearman: 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 24/162 [00:29<02:50,  1.23s/it, loss=0.0886]"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for tokens, labels in data_loader:\n",
    "            outputs = model(tokens)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * tokens.size(0)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return running_loss / len(data_loader.dataset), all_preds, all_labels\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    train_loss = train_epoch(combined_model, train_loader, optimizer, criterion)\n",
    "    # Evaluate on training data\n",
    "    train_loss_eval, train_preds, train_labels = evaluate(combined_model, train_loader, criterion)\n",
    "    train_spearman, _ = spearmanr(train_preds, train_labels)\n",
    "    # Evaluate on validation data\n",
    "    val_loss, val_preds, val_labels = evaluate(combined_model, valid_loader, criterion)\n",
    "    val_spearman, _ = spearmanr(val_preds, val_labels)\n",
    "    print(f\"Epoch {epoch+1}/{config['num_epochs']}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Spearman: {train_spearman:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Spearman: {val_spearman:.4f}\")\n",
    "    #take the one with least val_loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = combined_model.state_dict()\n",
    "\n",
    "# Load the best model state after training\n",
    "combined_model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNX78OGrRZ46"
   },
   "source": [
    "## 3. Preparing For Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset \n",
    "class ProteinTestDataset(Dataset):\n",
    "    def __init__(self, df, wt_seq):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.wt_seq = wt_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        mutation = row['mutant']\n",
    "        mutated_seq = generate_mutant_sequence(self.wt_seq, mutation)\n",
    "        return mutated_seq\n",
    "\n",
    "test_dataset = ProteinTestDataset(df_test, sequence_wt)\n",
    "# For test set, create a simple collate that tokenizes the sequences\n",
    "def test_collate_fn(batch):\n",
    "    batch_data = [(\"protein{}\".format(i), seq) for i, seq in enumerate(batch)]\n",
    "    _, _, tokens = batch_converter(batch_data)\n",
    "    tokens = tokens.to(device)\n",
    "    return tokens, None\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=test_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the set of mutants already present in your updated training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_mutants \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mdf_train\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutant\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Filter the test set to get only candidates not in the training data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m query_candidates \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;241m~\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutant\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_mutants)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Generating a new query list (#1 randomly):\n",
    "\n",
    "# Got the set of mutants already present in our updated training data\n",
    "train_mutants = set(df_train['mutant'].unique())\n",
    "\n",
    "# Filtered the test set to get only candidates not in the training data\n",
    "query_candidates = df_test[~df_test['mutant'].isin(train_mutants)]\n",
    "\n",
    "# Sample up to 100 new mutants\n",
    "num_queries = min(100, len(query_candidates))\n",
    "query_mutants = query_candidates.sample(n=num_queries, random_state=42)['mutant'].tolist()\n",
    "\n",
    "# Save the list of mutants to query.txt \n",
    "with open(\"query.txt\", \"w\") as f:\n",
    "    for mut in query_mutants:\n",
    "        f.write(mut + \"\\n\")\n",
    "\n",
    "print(\"query.txt generated with\", len(query_mutants), \"mutants.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty method \n",
    "def mc_dropout_inference(model, tokens, num_samples=10):\n",
    "    model.train()  \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            preds.append(model(tokens))\n",
    "    preds = torch.stack(preds, dim=0)  # get multiple predictions for each mutant\n",
    "    mean_pred = preds.mean(dim=0)       #average all predictions \n",
    "    uncertainty = preds.std(dim=0)      # compute std dev as uncertainty\n",
    "    return mean_pred, uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Dropout Inference: 100%|██████████| 1416/1416 [2:06:54<00:00,  5.38s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_preds = []\n",
    "all_uncertainties = []\n",
    "combined_model.eval()  \n",
    "\n",
    "\n",
    "#run dropout on testset\n",
    "for tokens, _ in tqdm(test_loader, desc=\"MC Dropout Inference\"):\n",
    "    mean_pred, uncertainty = mc_dropout_inference(combined_model, tokens, num_samples=10)\n",
    "    all_preds.extend(mean_pred.cpu().numpy())\n",
    "    all_uncertainties.extend(uncertainty.cpu().numpy())\n",
    "\n",
    "# add predictions and uncertainty to test dataframe\n",
    "df_test['DMS_score_predicted'] = all_preds\n",
    "df_test['uncertainty'] = all_uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query.txt generated with 100 mutants.\n"
     ]
    }
   ],
   "source": [
    "#generate top100 for query submission (#2 order by highest uncertainty score)\n",
    "\n",
    "# get mutants already in training set\n",
    "train_mutants = set(df_train['mutant'].unique())\n",
    "\n",
    "# filter test set to include only mutants not already in training data\n",
    "query_candidates = df_test[~df_test['mutant'].isin(train_mutants)]\n",
    "\n",
    "# sort the remaining candidates by uncertainty \n",
    "query_candidates = query_candidates.sort_values('uncertainty', ascending=False)\n",
    "\n",
    "# select top 100 mutants\n",
    "query_mutants = query_candidates.head(100)['mutant'].tolist()\n",
    "\n",
    "# save the query list to query.txt\n",
    "with open(\"query.txt\", \"w\") as f:\n",
    "    for mut in query_mutants:\n",
    "        f.write(mut + \"\\n\")\n",
    "\n",
    "print(\"query.txt generated with\", len(query_mutants), \"mutants.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions.csv generated with 11324 entries.\n"
     ]
    }
   ],
   "source": [
    "# Select only the relevant columns\n",
    "predictions_df = df_test[['mutant', 'DMS_score_predicted']]\n",
    "\n",
    "# Save as CSV\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"predictions.csv generated with\", predictions_df.shape[0], \"entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mutant  DMS_score_predicted\n",
      "2423  L134R             0.702731\n",
      "4890  L300W             0.699369\n",
      "2418  L134K             0.697462\n",
      "2374  R131H             0.696087\n",
      "4227  F256M             0.694895\n"
     ]
    }
   ],
   "source": [
    "#generate top100 for query submission (#3 order by highest DMS score)\n",
    "\n",
    "# Load our predictions \n",
    "df_preds = pd.read_csv('predictions.csv') \n",
    "\n",
    "# Sort by predicted DMS \n",
    "df_preds_sorted = df_preds.sort_values(by='DMS_score_predicted', ascending=False)\n",
    "\n",
    "# Remove mutants that are already in the training set\n",
    "mutants_in_train = df_train['mutant'].unique()\n",
    "df_preds_filtered = df_preds_sorted[~df_preds_sorted['mutant'].isin(mutants_in_train)]\n",
    "\n",
    "# Print results\n",
    "print(df_preds_filtered.head())\n",
    "\n",
    "#save to query3.txt\n",
    "df_preds_filtered['mutant'].head(100).to_csv('query3.txt', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load original train.csv as df_train_raw for top10.txt creation below\n",
    "\n",
    "df_train_raw = pd.read_csv('train.csv')\n",
    "df_train_raw['sequence'] = df_train_raw.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top10.txt generated with mutants:\n",
      "['L134R', 'L300W', 'L134K', 'R131H', 'F256M', 'T243F', 'R593P', 'T243Y', 'R593G', 'W632G']\n"
     ]
    }
   ],
   "source": [
    "# Generate top10.txt for query submission\n",
    "\n",
    "#remove the ones already in train.csv\n",
    "train_mutants = set(df_train_raw['mutant'].unique())\n",
    "query_candidates = predictions_df[~predictions_df['mutant'].isin(train_mutants)]\n",
    "# Select the top 10 based on DMS\n",
    "top10_df = query_candidates.sort_values('DMS_score_predicted', ascending=False).head(10)\n",
    "\n",
    "#create top10.txt file\n",
    "with open(\"top10.txt\", \"w\") as f:\n",
    "    for mutant in top10_df['mutant']:\n",
    "        f.write(mutant + \"\\n\")\n",
    "print(\"top10.txt generated with mutants:\")\n",
    "print(top10_df['mutant'].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
